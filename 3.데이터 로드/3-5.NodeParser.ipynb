{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter 2가지 소개\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "LlamaIndex는 대규모 언어 모델(LLM)을 사용하여 개인 데이터를 처리하는 데이터 프레임워크입니다. 이 프레임워크는 데이터 수집부터 처리, 검색까지 전체 과정을 지원합니다.\n",
    "\n",
    "주요 구성 요소는 다음과 같습니다:\n",
    "Documents는 원시 데이터를 표현하는 기본 단위입니다. 텍스트 파일, PDF, 웹페이지 등 다양한 소스의 데이터를 포함할 수 있습니다.\n",
    "Nodes는 Documents를 더 작은 단위로 분할한 것으로, LLM이 효과적으로 처리할 수 있는 크기입니다.\n",
    "\n",
    "데이터 처리 과정은 다음과 같습니다:\n",
    "먼저 데이터 로더를 사용하여 Documents를 생성합니다. 그 다음 Node Parser를 통해 Documents를 Nodes로 분할합니다.\n",
    "마지막으로 인덱스를 구축하여 효율적인 검색이 가능하도록 합니다.\n",
    "\n",
    "LlamaIndex는 다양한 인덱스 유형을 제공합니다. VectorStoreIndex는 임베딩 기반 검색을, SummaryIndex는 요약 기반 검색을 지원합니다.\n",
    "또한 하이브리드 검색, 재순위화 등 고급 검색 기능도 제공하여 검색 품질을 향상시킬 수 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TokenTextSplitter 결과 ===\n",
      "\n",
      "Node 1:\n",
      "LlamaIndex는 대규모 언어 모델(LLM)을 사용하여 개인 데이터를 처리하는 데이터 프레임워크입니다. 이 프레임워크는 데이터 수집부터 처리, 검색까지 전체 과정을 지원합니다.\n",
      "\n",
      "주요 구성 요소는 다음과 같습니다:\n",
      "Documents는 원시 데이터를 표현하는 기본\n",
      "\n",
      "Node 2:\n",
      "같습니다:\n",
      "Documents는 원시 데이터를 표현하는 기본 단위입니다. 텍스트 파일, PDF, 웹페이지 등 다양한 소스의 데이터를 포함할 수 있습니다.\n",
      "Nodes는 Documents를 더 작은 단위로 분할한 것으로, LLM이 효과적으로 처리할 수 있는 크기입니다.\n",
      "\n",
      "데이터 처리 과정은 다음과\n",
      "\n",
      "Node 3:\n",
      "처리할 수 있는 크기입니다.\n",
      "\n",
      "데이터 처리 과정은 다음과 같습니다:\n",
      "먼저 데이터 로더를 사용하여 Documents를 생성합니다. 그 다음 Node Parser를 통해 Documents를 Nodes로 분할합니다.\n",
      "마지막으로 인덱스를 구축하여 효율적인 검색이 가능하도록 합니다.\n",
      "\n",
      "LlamaIndex는 다양한\n",
      "\n",
      "Node 4:\n",
      "검색이 가능하도록 합니다.\n",
      "\n",
      "LlamaIndex는 다양한 인덱스 유형을 제공합니다. VectorStoreIndex는 임베딩 기반 검색을, SummaryIndex는 요약 기반 검색을 지원합니다.\n",
      "또한 하이브리드 검색, 재순위화 등 고급 검색 기능도 제공하여 검색\n",
      "\n",
      "Node 5:\n",
      "등 고급 검색 기능도 제공하여 검색 품질을 향상시킬 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. TokenTextSplitter (토큰 기반 분할)\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=20  # 노드 크기 (토큰 수)  # 노드 간 중복 토큰 수\n",
    ")\n",
    "token_nodes = token_splitter.split_text(text)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== TokenTextSplitter 결과 ===\")\n",
    "for i, node in enumerate(token_nodes, 1):\n",
    "    print(f\"\\nNode {i}:\")\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SentenceSplitter 결과 ===\n",
      "\n",
      "Node 1:\n",
      "LlamaIndex는 대규모 언어 모델(LLM)을 사용하여 개인 데이터를 처리하는 데이터 프레임워크입니다. 이 프레임워크는 데이터 수집부터 처리, 검색까지 전체 과정을 지원합니다.\n",
      "\n",
      "Node 2:\n",
      "주요 구성 요소는 다음과 같습니다:\n",
      "Documents는 원시 데이터를 표현하는 기본 단위입니다. 텍스트 파일, PDF, 웹페이지 등 다양한 소스의 데이터를 포함할 수 있습니다.\n",
      "\n",
      "Node 3:\n",
      "Nodes는 Documents를 더 작은 단위로 분할한 것으로, LLM이 효과적으로 처리할 수 있는 크기입니다.\n",
      "\n",
      "데이터 처리 과정은 다음과 같습니다:\n",
      "먼저 데이터 로더를 사용하여 Documents를 생성합니다. 그 다음 Node Parser를 통해 Documents를 Nodes로 분할합니다.\n",
      "\n",
      "Node 4:\n",
      "그 다음 Node Parser를 통해 Documents를 Nodes로 분할합니다.\n",
      "마지막으로 인덱스를 구축하여 효율적인 검색이 가능하도록 합니다.\n",
      "\n",
      "LlamaIndex는 다양한 인덱스 유형을 제공합니다.\n",
      "\n",
      "Node 5:\n",
      "VectorStoreIndex는 임베딩 기반 검색을, SummaryIndex는 요약 기반 검색을 지원합니다.\n",
      "또한 하이브리드 검색, 재순위화 등 고급 검색 기능도 제공하여 검색 품질을 향상시킬 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2. SentenceSplitter (문장 단위 분할)\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=100, chunk_overlap=20  # 노드 크기  # 노드 간 중복 크기\n",
    ")\n",
    "sentence_nodes = sentence_splitter.split_text(text)\n",
    "\n",
    "print(\"\\n=== SentenceSplitter 결과 ===\")\n",
    "for i, node in enumerate(sentence_nodes, 1):\n",
    "    print(f\"\\nNode {i}:\")\n",
    "    print(node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
